import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, roc_curve, auc
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from mlxtend.plotting import plot_decision_regions

st.title("üë®‚Äçüíºüí∏üë©‚Äçüíº–ê–Ω–∞–ª–∏–∑ –∑–∞—è–≤–æ–∫ –Ω–∞ –∫—Ä–µ–¥–∏—Ç")
st.write(
    """
    –≠—Ç–æ Streamlit‚Äë–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —Ä–µ–∞–ª–∏–∑—É–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –∏ –∞–Ω–∞–ª–∏–∑ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö "–û–¥–æ–±—Ä–µ–Ω–∏–µ –∫—Ä–µ–¥–∏—Ç–∞" (UCI).
    –í –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è –∑–∞–≥—Ä—É–∑–∫–∞, –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö, –æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –æ–±—É—á–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π,
    –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è 3D —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è, –≥—Ä–∞–Ω–∏—Ü —Ä–µ—à–µ–Ω–∏–π –∏ ROC-–∫—Ä–∏–≤—ã—Ö. –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –ø–æ–∑–≤–æ–ª—è—é—Ç –º–µ–Ω—è—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–µ–π.
    """
)

# –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
st.sidebar.header("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã")

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –≤—ã–±–æ—Ä–∫–∏
test_size = st.sidebar.slider("–î–æ–ª—è —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ (test_size)", 0.1, 0.2, 0.3, 0.15)

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–µ–π
k_neighbors = st.sidebar.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Å–µ–¥–µ–π –¥–ª—è kNN", 1, 15, 3, 1)
max_depth = st.sidebar.slider("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤–∞", 1, 20, 5, 1)
max_iter = st.sidebar.slider("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –∏—Ç–µ—Ä–∞—Ü–∏–π (Logistic Regression)", 100, 1000, 565, 50)

# –§—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –ø–µ—Ä–≤–∏—á–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
@st.cache_data
def load_data():
    url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data'
    df = pd.read_csv(url, header=None, na_values='?')
    # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –≤ —Ç–∞—Ä–≥–µ—Ç–µ (—Å—Ç–æ–ª–±–µ—Ü 15)
    df = df.dropna(subset=[15])
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤—Å–µ –æ–±—ä–µ–∫—Ç–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã (–∫—Ä–æ–º–µ —Ç–∞—Ä–≥–µ—Ç–∞) –≤ —á–∏—Å–ª–æ–≤—ã–µ, –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ
    for col in df.columns:
        if col != 15 and df[col].dtype == 'object':
            df[col] = pd.to_numeric(df[col], errors='coerce')
    # –£–¥–∞–ª—è–µ–º —Å—Ç–æ–ª–±—Ü—ã, —Å–æ—Å—Ç–æ—è—â–∏–µ —Ç–æ–ª—å–∫–æ –∏–∑ NaN
    df.dropna(axis=1, how='all', inplace=True)
    # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏ –≤ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö –ø–æ –≥—Ä—É–ø–ø–µ —Ç–∞—Ä–≥–µ—Ç–∞
    num_cols = [col for col in df.columns if col != 15 and pd.api.types.is_numeric_dtype(df[col])]
    df[num_cols] = df.groupby(15)[num_cols].transform(lambda x: x.fillna(x.mean()))
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–∞—Ä–≥–µ—Ç: '+' ‚Üí 1, '-' ‚Üí 0
    df[15] = df[15].map({'+': 1, '-': 0})
    return df

data = load_data()

# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
st.subheader("–û–±–∑–æ—Ä –¥–∞–Ω–Ω—ã—Ö")
st.write(f"–†–∞–∑–º–µ—Ä –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö: {data.shape}")
st.dataframe(data.head(10))

# –û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ (–∏–∑ —á–∏—Å–ª–æ–≤—ã—Ö, —Å –±–æ–ª–µ–µ —á–µ–º 10 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π)
num_features = [col for col in data.columns if col != 15 and data[col].nunique() > 10]
corr = {col: data[col].corr(data[15]) for col in num_features}
sorted_features = sorted(corr.items(), key=lambda x: abs(x[1]), reverse=True)
top3_features = sorted_features[:3]

st.write("**–¢—Ä–∏ –Ω–∞–∏–±–æ–ª–µ–µ –∑–Ω–∞—á–∏–º—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞ (–ø–æ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ —Å —Ç–∞—Ä–≥–µ—Ç–æ–º):**")
for feature, corr_value in top3_features:
    st.write(f"–ü—Ä–∏–∑–Ω–∞–∫ {feature}: –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è {corr_value:.3f}")

# –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≤—ã–±–æ—Ä –¥–≤—É—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
st.sidebar.subheader("–í—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
numeric_cols = [col for col in data.columns if col != 15 and pd.api.types.is_numeric_dtype(data[col])]
default_feats = [10, 7] if 10 in numeric_cols and 7 in numeric_cols else numeric_cols[:2]
selected_features = st.sidebar.multiselect(
    "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–æ–≤–Ω–æ 2 –ø—Ä–∏–∑–Ω–∞–∫–∞ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏",
    options=numeric_cols,
    default=default_feats
)
if len(selected_features) != 2:
    st.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ —Ä–æ–≤–Ω–æ 2 –ø—Ä–∏–∑–Ω–∞–∫–∞!")
    st.stop()

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
X = data[selected_features]
y = data[15]
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=test_size, random_state=42, stratify=y
)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
st.subheader("–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π")
models = [
    ("kNN", KNeighborsClassifier(n_neighbors=k_neighbors)),
    ("Logistic Regression", LogisticRegression(max_iter=max_iter)),
    ("Decision Tree", DecisionTreeClassifier(max_depth=max_depth, random_state=42))
]

results = {}
for name, model in models:
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)
    acc = accuracy_score(y_test, y_pred)
    # ROC-–∫—Ä–∏–≤–∞—è (–µ—Å–ª–∏ –º–æ–¥–µ–ª—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç predict_proba)
    if hasattr(model, "predict_proba"):
        y_prob = model.predict_proba(X_test_scaled)[:, 1]
        fpr, tpr, _ = roc_curve(y_test, y_prob)
        roc_auc = auc(fpr, tpr)
    else:
        fpr, tpr, roc_auc = None, None, None
    results[name] = {
        "model": model,
        "accuracy": acc,
        "report": classification_report(y_test, y_pred, output_dict=True),
        "fpr": fpr,
        "tpr": tpr,
        "roc_auc": roc_auc
    }
    st.write(f"**{name}** ‚Äî Accuracy: {acc:.3f}, AUC: {roc_auc:.3f}" if roc_auc else f"**{name}** ‚Äî Accuracy: {acc:.3f}")

# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞ –ø–æ –º–æ–¥–µ–ª—è–º
with st.expander("–ü–æ–∫–∞–∑–∞—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–π classification report –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"):
    for name, res in results.items():
        st.write(f"### {name}")
        st.text(classification_report(y_test, res["model"].predict(X_test_scaled)))

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è 3D —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ —Ç—Ä—ë–º –Ω–∞–∏–±–æ–ª–µ–µ –∑–Ω–∞—á–∏–º—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º
st.subheader("3D –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è (—Ç–æ–ø-3 –ø—Ä–∏–∑–Ω–∞–∫–∞ –ø–æ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏)")
features_3d = [feature for feature, _ in top3_features]
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')
markers = {1: 'o', 0: '^'}
colors  = {1: 'blue', 0: 'red'}
for cls in data[15].unique():
    data_cls = data[data[15] == cls]
    ax.scatter(
        data_cls[features_3d[0]],
        data_cls[features_3d[1]],
        data_cls[features_3d[2]],
        marker=markers[cls],
        color=colors[cls],
        label=f"–ö–ª–∞—Å—Å {cls}"
    )
ax.set_title("3D-–≥—Ä–∞—Ñ–∏–∫: –û–¥–æ–±—Ä–µ–Ω–∏–µ –∫—Ä–µ–¥–∏—Ç–∞ (UCI)")
ax.set_xlabel(f"–ü—Ä–∏–∑–Ω–∞–∫ {features_3d[0]}")
ax.set_ylabel(f"–ü—Ä–∏–∑–Ω–∞–∫ {features_3d[1]}")
ax.set_zlabel(f"–ü—Ä–∏–∑–Ω–∞–∫ {features_3d[2]}")
ax.legend()
st.pyplot(fig)

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–∞–Ω–∏—Ü —Ä–µ—à–µ–Ω–∏–π –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö 2 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
st.subheader("–ì—Ä–∞–Ω–∏—Ü—ã —Ä–µ—à–µ–Ω–∏–π –º–æ–¥–µ–ª–µ–π (2D)")
fig2, axes = plt.subplots(3, 1, figsize=(8, 16))
for i, (name, model) in enumerate(models):
    ax = axes[i]
    plot_decision_regions(X_train_scaled, y_train.values, clf=model, legend=2, ax=ax)
    ax.set_xlabel(str(selected_features[0]))
    ax.set_ylabel(str(selected_features[1]))
    ax.set_title(f"–ì—Ä–∞–Ω–∏—Ü—ã —Ä–µ—à–µ–Ω–∏–π: {name}")
plt.tight_layout()
st.pyplot(fig2)

# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ ROC-–∫—Ä–∏–≤—ã—Ö
st.subheader("ROC-–∫—Ä–∏–≤—ã–µ –¥–ª—è –º–æ–¥–µ–ª–µ–π")
fig3, ax3 = plt.subplots(figsize=(8, 6))
for name, res in results.items():
    if res["roc_auc"] is not None:
        ax3.plot(res["fpr"], res["tpr"], label=f"{name} (AUC = {res['roc_auc']:.3f})")
ax3.plot([0, 1], [0, 1], linestyle='--', color='gray', label='–°–ª—É—á–∞–π–Ω–æ–µ —É–≥–∞–¥—ã–≤–∞–Ω–∏–µ')
ax3.set_title("ROC-–∫—Ä–∏–≤—ã–µ (—Ç–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞)")
ax3.set_xlabel("False Positive Rate")
ax3.set_ylabel("True Positive Rate")
ax3.legend(loc="lower right")
st.pyplot(fig3)
